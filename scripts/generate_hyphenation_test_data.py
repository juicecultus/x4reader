"""
Generate hyphenation test data from a text file.

This script extracts unique words from a book and generates ground truth
hyphenations using the pyphen library, which can be used to test and validate
the German hyphenation implementation.

Usage:
    python generate_hyphenation_test_data.py <input_file> <output_file> [--language de_DE]

Requirements:
    pip install pyphen
"""

import argparse
import re
from collections import Counter
import pyphen
from pathlib import Path


def extract_words(text):
    """Extract all words from text, preserving original case."""
    # Find all sequences of letters (including umlauts and ß)
    words = re.findall(r"[a-zA-ZäöüÄÖÜß]+", text)
    return words


def clean_word(word):
    """Normalize word for hyphenation testing."""
    # Keep original case but strip any non-letter characters
    return word.strip()


def generate_hyphenation_data(
    input_file, output_file, language="de_DE", min_length=6, max_words=None
):
    """
    Generate hyphenation test data from a text file.

    Args:
        input_file: Path to input text file
        output_file: Path to output file with hyphenation data
        language: Language code for pyphen (e.g., 'de_DE', 'en_US')
        min_length: Minimum word length to include
        max_words: Maximum number of words to include (None for all)
    """
    print(f"Reading from: {input_file}")

    # Read the input file
    with open(input_file, "r", encoding="utf-8") as f:
        text = f.read()

    # Extract words
    print("Extracting words...")
    words = extract_words(text)
    print(f"Found {len(words)} total words")

    # Count word frequencies
    word_counts = Counter(words)
    print(f"Found {len(word_counts)} unique words")

    # Initialize pyphen hyphenator
    print(f"Initializing hyphenator for language: {language}")
    try:
        hyphenator = pyphen.Pyphen(lang=language)
    except KeyError:
        print(f"Error: Language '{language}' not found in pyphen.")
        print("Available languages include: de_DE, en_US, en_GB, fr_FR, etc.")
        return

    # Generate hyphenations
    print("Generating hyphenations...")
    hyphenation_data = []

    # Sort by frequency (most common first) then alphabetically
    sorted_words = sorted(word_counts.items(), key=lambda x: (-x[1], x[0].lower()))

    for word, count in sorted_words:
        # Filter by minimum length
        if len(word) < min_length:
            continue

        # Get hyphenation
        hyphenated = hyphenator.inserted(word, hyphen="=")

        # Only include words that can be hyphenated (contain at least one hyphen point)
        if "=" in hyphenated:
            hyphenation_data.append(
                {"word": word, "hyphenated": hyphenated, "count": count}
            )

        # Stop if we've reached max_words
        if max_words and len(hyphenation_data) >= max_words:
            break

    print(f"Generated {len(hyphenation_data)} hyphenated words")

    # Write output file
    print(f"Writing to: {output_file}")
    with open(output_file, "w", encoding="utf-8") as f:
        # Write header with metadata
        f.write(f"# Hyphenation Test Data\n")
        f.write(f"# Source: {Path(input_file).name}\n")
        f.write(f"# Language: {language}\n")
        f.write(f"# Total words: {len(hyphenation_data)}\n")
        f.write(f"# Format: word | hyphenated_form | frequency_in_source\n")
        f.write(f"#\n")
        f.write(f"# Hyphenation points are marked with '='\n")
        f.write(f"# Example: Silbentrennung -> Sil=ben=tren=nung\n")
        f.write(f"#\n\n")

        # Write data
        for item in hyphenation_data:
            f.write(f"{item['word']}|{item['hyphenated']}|{item['count']}\n")

    print("Done!")

    # Print some statistics
    print("\n=== Statistics ===")
    print(f"Total unique words extracted: {len(word_counts)}")
    print(f"Words with hyphenation points: {len(hyphenation_data)}")
    print(
        f"Average hyphenation points per word: {sum(h['hyphenated'].count('=') for h in hyphenation_data) / len(hyphenation_data):.2f}"
    )

    # Print some examples
    print("\n=== Examples (first 10) ===")
    for item in hyphenation_data[:10]:
        print(
            f"  {item['word']:20} -> {item['hyphenated']:30} (appears {item['count']}x)"
        )


def main():
    parser = argparse.ArgumentParser(
        description="Generate hyphenation test data from a text file",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate test data from a German book
  python generate_hyphenation_test_data.py ../data/books/bobiverse_1.txt hyphenation_test_data.txt
  
  # Limit to 500 most common words
  python generate_hyphenation_test_data.py ../data/books/bobiverse_1.txt hyphenation_test_data.txt --max-words 500
  
  # Use English hyphenation (when available)
  python generate_hyphenation_test_data.py book.txt test_en.txt --language en_US
        """,
    )

    parser.add_argument("input_file", help="Input text file to extract words from")
    parser.add_argument("output_file", help="Output file for hyphenation test data")
    parser.add_argument(
        "--language", default="de_DE", help="Language code (default: de_DE)"
    )
    parser.add_argument(
        "--min-length", type=int, default=6, help="Minimum word length (default: 6)"
    )
    parser.add_argument(
        "--max-words",
        type=int,
        help="Maximum number of words to include (default: all)",
    )

    args = parser.parse_args()

    generate_hyphenation_data(
        args.input_file,
        args.output_file,
        language=args.language,
        min_length=args.min_length,
        max_words=args.max_words,
    )


if __name__ == "__main__":
    main()
